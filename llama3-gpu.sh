docker exec -it ollama-gpu ollama run llama2:70b
